{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "import dataclasses\n",
    "@dataclasses.dataclass\n",
    "class State:\n",
    "    distance: tuple\n",
    "    target_position: tuple\n",
    "    obstacle_position: str\n",
    "    target: tuple\n",
    "\n",
    "\n",
    "class RL(object):\n",
    "    def __init__(self, height_squares, width_squares, square_size):\n",
    "        \n",
    "\n",
    "        # Bellman eqn parameters \n",
    "        self.e = 0.1 #epsilon\n",
    "        self.lr = 0.5 #learning rate (between 0 and 1)\n",
    "        self.df = 0.1 #discount factor (between 0 and 1)\n",
    "        \n",
    "        \n",
    "        # qvalue table\n",
    "        self.qvalues = self.read_qvalues()\n",
    "        self.qvalues_record = []\n",
    "\n",
    "        # Action space\n",
    "        self.actions = {\n",
    "            0:'up',\n",
    "            1:'left',\n",
    "            2:'down',\n",
    "            3:'right'\n",
    "        }\n",
    "\n",
    "        # Screen parameters\n",
    "        self.height_squares = height_squares\n",
    "        self.width_squares = width_squares\n",
    "        self.square_size = square_size\n",
    "        \n",
    "\n",
    "    def read_qvalues(self, path=\"qvalues.json\"):\n",
    "        with open(path, \"r\") as f:\n",
    "            qvalues = json.load(f)\n",
    "        return qvalues\n",
    "\n",
    "    def write_qvalues(self, path=\"qvalues.json\"):\n",
    "        with open(path, \"w\") as f:\n",
    "            json.dump(self.qvalues, f)\n",
    "            \n",
    "    def choose_action(self, chaser, target):\n",
    "        \n",
    "        state = self.state_params(chaser, target)\n",
    "\n",
    "        #Epsilon greedy policy (exploration and exploitation balance)\n",
    "        n = random.uniform(0,1)\n",
    "        \n",
    "        #exploration\n",
    "        if n < self.e:\n",
    "            action_key = random.choices(list(self.actions.keys()))[0]  #chooses one of four actions randomly\n",
    "        #explotation\n",
    "        else:\n",
    "            qvals_current_state=self.qvalues[self.state_str(state)]\n",
    "            max_q_val=max(qvals_current_state)\n",
    "            action_key = qvals_current_state.index(max_q_val) #chooses action with max q value\n",
    "            \n",
    "            \n",
    "        action = self.actions[action_key]\n",
    "        self.qvalues_record.append({'state': state, 'action': action_key})\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    \n",
    "    \n",
    "    def Reset(self):\n",
    "        self.qvalues_record = []\n",
    "        \n",
    "        \n",
    "    \n",
    "    def New_q_vals(self, reason):\n",
    "        \n",
    "        qvalues_record = self.qvalues_record[::-1] \n",
    "        \n",
    "        for indx, record_element in enumerate(qvalues_record[:-1]):\n",
    "            \n",
    "            #reward and q value update when the chaser runs into its body\n",
    "            if reason: # only when chaser meets a wall or runs into its own body\n",
    "                current_state = qvalues_record[0]['state']\n",
    "                current_action= qvalues_record[0]['action']\n",
    "                state_str = self.state_str(current_state)\n",
    "                reward = -1\n",
    "                # Bellman equation\n",
    "                self.qvalues[state_str][current_action] = self.qvalues[state_str][current_action] + self.lr * (reward - self.qvalues[state_str][current_action])\n",
    "                #after update reset reason to none \n",
    "                reason = None\n",
    "            \n",
    "            else:\n",
    "                current_state = record_element['state'] \n",
    "                previous_state = qvalues_record[indx+1]['state'] \n",
    "                previous_action = qvalues_record[indx+1]['action'] \n",
    "                \n",
    "                #distance chaser-target at current state\n",
    "                horizontal_dist_curr = current_state.distance[0]\n",
    "                vertica_dist_curr = current_state.distance[1] \n",
    "                #distance chaser-target at previous state\n",
    "                horizontal_dist_prev = previous_state.distance[0] \n",
    "                vertica_dist_prev = previous_state.distance[1] \n",
    "                \n",
    "                \n",
    "                #reward if the chaser found the target\n",
    "                if previous_state.target != current_state.target: \n",
    "                    reward = 1\n",
    "                #reward if chaser is closer to the target\n",
    "                elif (abs(horizontal_dist_prev) > abs(horizontal_dist_curr) or abs(vertica_dist_prev) > abs(vertica_dist_curr)): \n",
    "                    reward = 1\n",
    "                #reward if chaser is further from the target\n",
    "                else:\n",
    "                    reward = -1 \n",
    "                       \n",
    "                \n",
    "                # Bellman equation\n",
    "                state_str = self.state_str(previous_state)\n",
    "                next_state_string = self.state_str(current_state)\n",
    "                self.qvalues[state_str][previous_action] = self.qvalues[state_str][previous_action] + self.lr * (reward + self.df*max(self.qvalues[next_state_string]) -self.qvalues[state_str][previous_action]) \n",
    "\n",
    "\n",
    "    def state_params(self, chaser, target):\n",
    "        \n",
    "      #states for the position of chaser relative to the target\n",
    "        #measure the vertical and horizontal distance between the chaser and the target\n",
    "        chaser_head = chaser[-1]\n",
    "        vertical_dist = target[1] - chaser_head[1]\n",
    "        horizontal_dist = target[0] - chaser_head[0]\n",
    "\n",
    "        if vertical_dist < 0:\n",
    "            pos_u = '1' # target is above chaser\n",
    "        else:\n",
    "            pos_u = '0' #target is NOT above the chaser\n",
    "            \n",
    "        \n",
    "        if horizontal_dist < 0:\n",
    "            pos_l = '1' # target is to the left of the chaser\n",
    "        else:\n",
    "            pos_l = '0' #target is NOT to the left of the chaser\n",
    "            \n",
    "            \n",
    "        if vertical_dist > 0:\n",
    "            pos_d = '1' # target is below chaser\n",
    "        else:\n",
    "            pos_d = '0' #target is NOT below the chaser\n",
    "        \n",
    "        \n",
    "        if horizontal_dist > 0:\n",
    "            pos_r = '1' # target is to the right of the chaser\n",
    "        else:\n",
    "            pos_r = '0' #target is NOT in the right of the chaser\n",
    "        \n",
    "        \n",
    "      #states for the position of chaser relative to the walls and chaser body   \n",
    "        surrounding_positions = [\n",
    "            (chaser_head[0]-21, chaser_head[1]),   # square to the left of chaser head\n",
    "            (chaser_head[0]+21, chaser_head[1]),   #square to the right of chaser head      \n",
    "            (chaser_head[0],                  chaser_head[1]-21), #square above the chaser head\n",
    "            (chaser_head[0],                  chaser_head[1]+21), #square below the chaser head\n",
    "        ]\n",
    "        \n",
    "        obstacle_position_list = []\n",
    "        for sq in surrounding_positions:\n",
    "            if sq[0] < 0 or sq[1] < 0 or sq[0] >= self.width_squares or sq[1] >= self.height_squares: # if the walls are left, above, right or below\n",
    "                obstacle_position_list.append('1')\n",
    "            elif sq in chaser[:-1]: # if the chaser body is left, right, below or above\n",
    "                obstacle_position_list.append('1')\n",
    "            else:\n",
    "                obstacle_position_list.append('0')\n",
    "        obstacle_position = ''.join(obstacle_position_list)\n",
    "\n",
    "        return State((horizontal_dist, vertical_dist), (pos_u, pos_r, pos_d, pos_l), obstacle_position, target)\n",
    "\n",
    "    def state_str(self, state):\n",
    "        return str((state.target_position[0],state.target_position[1],state.target_position[2],state.target_position[3],state.obstacle_position))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
